lines <- readLines(url, n=10)
#w <- c(1, 9, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3, 5, 4, 1, 3)
#colNames <- c("filler", "week", "filler", "sstNino12", "filler", "sstaNino12", "filler", "sstNino3", "filler", "sstaNino3", "filler", "sstNino34", "filler", "sstaNino34", "filler", "sstNino4", "filler", "sstaNino4")
wth<-c(-1,9,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3)
colNames<-c("Week","col1","col2","col3","col4","col5","col6","col7","col8")
d <- read.fwf(url, wth, header=FALSE, skip=4, col.names=colNames)
head(d)
sum(d$col3)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
colNames<-c("Week","col1","col2","col3","col4","col5","col6","col7","col8")
d <- read.fwf(url, wth, header=FALSE, skip=4, col.names=colNames)
sum(d$col3)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
colNames<-c("Week","col1","col2","col3","col4","col5","col6","col7","col8")
d <- read.fwf(url, wth, header=FALSE, skip=4, col.names=colNames)
head(lines)
head(d)
sum(d$col3)
url <- "https://d396qusza40orc.cloudfront.net/getdata%2Fwksst8110.for"
lines <- readLines(url, n=10)
wth<-c(-1,9,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3,-5,4,-1,3)
colNames<-c("Week","col1","col2","col3","col4","col5","col6","col7","col8")
d <- read.fwf(url, wth, header=FALSE, skip=4, col.names=colNames)
head(lines)
head(d)
sum(d$col3) #because de column 1 is week
myapp <- oauth_app("Testquiz2", "6068ed8bed63058cbc72", secret="ba2e7664ec45d8705a2d5601d11b9025a66fca4c")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
library(httr)
require(httpuv)
require(jsonlite)
# 1. Find OAuth settings for github:
#    http://developer.github.com/v3/oauth/
oauth_endpoints("github")
# 2. Register an application at https://github.com/settings/applications
#    Insert your values below - if secret is omitted, it will look it up in
#    the GITHUB_CONSUMER_SECRET environmental variable.
#
#    Use http://localhost:1410 as the callback url
myapp <- oauth_app("Testquiz2", "6068ed8bed63058cbc72", secret="ba2e7664ec45d8705a2d5601d11b9025a66fca4c")
# 3. Get OAuth credentials
github_token <- oauth2.0_token(oauth_endpoints("github"), myapp)
# 4. Use API
gtoken <- config(token = github_token)
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/datasharing"))
stop_for_status(req)
content(req)
req <- with_config(gtoken, GET("https://api.github.com/users/jtleek/repos"))
stop_for_status(req)
content(req)
class(req)
str(req)
names(req)
req$content
names$req
req$headers
library("swirl")
swirl()
mydf<-read.csv(path2csv, stringsAsFactors = FALSE)
dim(mydf)
head(mydf)
library(dplyr)
packageVersion("dplyr")
cran <- tbl_df(mydf)
rm("mydf")
print(cran)
cran
?select
select(cran, ip_id, package, country)
5:20
select(cran, r_arch:country)
select(cran, country:r_arch)
cran
select(cran, -time)
-5:20
-(5:20)
select(cran,-(X:size))
filter(cran, package == "swirl")
filter(cran, r_version == "3.1.1", country == "US")
?Comparison
filter(cran, r_version <= "3.0.2", country == "IN")
filter(cran, country == "US" | country == "IN")
filter(cran, size > 100500, r_os == "linux-gnu")
is.na(c(3, 5, NA, 10))
!is.na(c(3, 5, NA, 10))
filter(cran,!is.na(r_version))
cran2<-select(cran,size:ip_id)
arrange(cran2, ip_id)
arrange(cran2, desc(ip_id))
arrange(cran2, package, ip_id)
arrange(cran2,country,r_version(desc),ip_id)
arrange(cran2,country,desc(r_version),ip_id)
cran3<-select(ip_id,package,size)
cran3<-select(cran,ip_id,package,size)
cran3
mutate(cran3,size_mb = size / 2^20)
mutate(cran3,size_mb = size / 2^20,size_gb = size_mb / 2^10)
mutate(cran3,correct_size = size - 1000)
mutate(cran3,correct_size = size + 1000)
summarize(cran, avg_bytes = mean(size))
library(dplyr)
cran<-tbl_df(mydf)
rm("mydf")
cran
?group_by
by_package<-group_by(cran,package)
by_package
summarize(by_package,mean(size))
avg_bytes = mean(size))
pack_sum <- summarize(by_package,
count = n(),
unique =  n_distinct(ip_id) ,
countries = n_distinct(country),
avg_bytes = mean(size))
submit(summarize1)
source('C:/Users/Isabel/AppData/Local/Temp/Rtmp2b4b4B/summarize1.R')
summarize1
submit()
pack_sum
quantile(pack_sum$count, probs = 0.99)
filter(pack_sum,count>679)
top_counts<-filter(pack_sum, count > 679)
top_counts
View(top_counts)
top_counts_sorted<-arrange(top_counts,desc(count))
view(top_counts_sorted)
View(top_counts_sorted)
quantile(pack_sum$unique, probs = 0.99)
top_unique<-filter(pack_sum,unique > 465)
View(top_unique)
top_unique_sorted<-arrange(top_unique,desc(unique))
View(top_unique_sorted)
submit()
submit()
submit()
View(result3)
submit()
submit()
submit()
submit()
library(tidyr)
students
?gather
gather(students, sex, count, -grade)
students2
res<-gather(students2,sex_class,count,-grade)
res
?separate()
?separate
separate(data=res,col=sex_class,into=c("sex","class"))
submit()
submit()
submit()
submit()
students3
submit()
submit()
submit()
submit()
submit()
?spread
submit()
submit()
submit()
submit()
submit()
submit()
submit()
extract_numeric("class5")
submit()
submit()
submit()
students4
submit()
submit()
submit()
submit()
library("tidyr", lib.loc="~/R/win-library/3.2")
?unique
?unique
submit()
submit()
unique(select(students4,id, name, sex))
submit()
submit()
submit()
passed
failed
passed<-mutate(passed,status="passed")
failed<-mutate(failed,status="failed")
?bind_rows
bind_rows(list(passed,failed),.id="name")
bind_rows(list(passed,failed))
bind_rows(passed,failed)
sat
submit()
submit()
submit()
?group_by
submit()
library ("dplyr")
submit()
source('C:/Users/Isabel/AppData/Local/Temp/Rtmp2b4b4B/script9.R')
submit()
submit()
bye
library(jpeg)
library(data.table)
library(dplyr)
library(Hmisc)
install.packages("Hmisc")
library(jpeg)
library(data.table)
install.packages("jpeg")
library(jpeg)
library(data.table)
library(dplyr)
library(Hmisc)
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
dst1 = 'q1.csv'
download.file(fileurl1, dst1, method = 'curl')
options('download.file.method'='curl')
download.file(fileurl1, dst1, method = 'auto')
data1 = read.csv(dst1)
View(data1)
agricultureLogical = data1$ACR == 3 & data1$AGS == 6
head(which(agricultureLogical), 3)
url ="https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
dest= 'q2.jpg'
download.file(url, dest, method = 'auto')
data2 = readJPEG(dest, native = TRUE)
url ="https://d396qusza40orc.cloudfront.net/getdata%2Fjeff.jpg"
dest= 'q2.jpg'
download.file(fileurl2, dest, mode = 'wb', method = 'auto')
download.file(url, dest, mode = 'wb', method = 'auto')
data2 = readJPEG(dest, native = TRUE)
quantile(data2, probs = c(0.3, 0.8))
fileurl3a = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst3a = 'q3a.csv'
fileurl3b = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
dst3b = 'q3b.csv'
download.file(fileurl3a, dst3a, method = 'auto')
download.file(fileurl3b, dst3b, method = 'auto')
gdp = fread(dst3a, skip=4, nrows = 190, select = c(1, 2, 4, 5), col.names=c("CountryCode", "Rank", "Economy", "Total"))
?fread
download.file(fileurl3a, dst3a,mode='wb', method = 'auto')
download.file(fileurl3b, dst3b,mode='wb', method = 'auto')
gdp = fread(dst3a, skip=4, nrows = 190, select = c(1, 2, 4, 5),
col.names=c("CountryCode", "Rank", "Economy", "Total"))
edu = fread(dst3b)
merge = merge(gdp, edu, by = 'CountryCode')
nrow(merge)
arrange(merge, desc(Rank))[13, Economy]
gdp
View(edu)
merge
View(merge)
nrow(merge)
arrange(merge, desc(Rank))[13, Economy]
tapply(merge$Rank, merge$`Income Group`, mean)
names(merge)
tapply(merge$Rank, merge$Income Group, mean)
tapply(merge$Rank, merge$`Income Group`, mean)
merge$RankGroups <- cut2(merge$Rank, g=5)
merge
table(merge$RankGroups, merge$`Income Group`)
names(merge)
merge$RankGroups
table(merge$RankGroups, merge$`Income Group`)
swirl()
install.packages("lubridate")
bye
install.packages("lubridate")
install.packages("lubridate")
library(lubridate)
swirl()
library(swirl)
swirl()
Sys.getlocale("LC_TIME")
library(lubridate)
help(package = lubridate)
today()
this_day <- today()
this_day
year(this_day)
wday(this_day)
wday(this_day,label=TRUE)
this_moement<-now()
this_moment<-now()
this_moment
hour(this_moment)
my_date<-ymd("1989-05-17")
my_date
class(my_date)
ymd( "1989 May 17")
mdy("March 12, 1975")
dmy(25081985)
ymd("192012")
ymd("1920-1-2")
dt1
ymd_hms(dt1)
hms(dt1)
hms("03:22:14")
dt2
ymd(dt2)
update(this_moment, hours = 8, minutes = 34, seconds = 55)
this_moment
this_moment<-update(this_moment,hours=19,,minutes=14)
this_moment<-update(this_moment,hours=19,minutes=14)
this_moment
nyc<-now(tzone="America/New_York")
nyc
depart<-nyc + days(2)
depart
depart<-update(depart,hours=17,minutes=34)
depart
arrive<-update(depart,hours=15,minutes=50)
arrive <- depart + hours(15) + minutes(50)
?with_tz
arrive<-with_tz(arrive,tzone="Asia/Hong_Kong")
arrive
last_time<-mdy("June 17, 2008",tz="Singapore")
last_time
?new_interval()
?new_interval
how_long<-new_interval(arrive-last_time)
how_long<-interval(arrive-last_time)
?interval
how_long<-interval(last_time,arrive)
how_long<-interval(last_time,arrive)
how_long<-new_interval(last_time,arrive)
as.period(how_long)
stopwatch()
bye
fileurl1 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2Fss06hid.csv'
dst1 = 'q41.csv'
options('download.file.method'='curl')
download.file(fileurl1, dst1, method = 'auto')
data1 = read.csv(dst1)
View(data1)
?strsplit
strsplit(data1,"wgtp")
splitNames=strsplit(names(data1),"wgtp")
splitNames
data1 = read.csv(dst1)
splitNames<-strsplit(data1,"wgtp")
splitNames=strsplit(names(data1),"wgtp")
splitNames[[123]]
fileurl2 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst2 = 'q42.csv'
download.file(fileurl2, dst2, method = 'auto')
data2 = read.csv(dst2)
View(data2)
names(data2)
gsub(",",".",data2)
gsub(",",".",data2$X.3)
data2 = data.table(read.csv(f, skip = 4, nrows = 215, stringsAsFactors = FALSE))
packages <- c("data.table", "quantmod")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
install.packages("quantmod")
install.packages("quantmod")
install.packages("quantmod")
packages <- c("data.table", "quantmod")
sapply(packages, require, character.only = TRUE, quietly = TRUE)
data2 = data.table(read.csv(dst2, skip = 4, nrows = 215, stringsAsFactors = FALSE))
View(data2)
data2 <- dtGDP[X != ""]
data2 <- data2[X != ""]
View(data2)
data2 <- data2[, list(X, X.1, X.3, X.4)]
View(data2)
setnames(data2, c("X", "X.1", "X.3", "X.4"), c("code", "ranking",
"name", "gdp"))
data2$gpd
View(data2)
data2$gpd
class(data2)
data2$gpd
gsub(",", "", data2$gdp)
as.numeric(gsub(",", "", data2$gdp))
as.numeric(gsub(",", ".", data2$gdp))
sum(as.numeric(gsub(",", ".", data2$gdp)))
sum(as.numeric(gsub(",", "", data2$gdp)))
gdp <- as.numeric(gsub(",", ".", data2$gdp))
mean(gdp, na.rm = TRUE)
fileurl2 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FGDP.csv'
dst2 = 'q42.csv'
download.file(fileurl2, dst2, method = 'auto')
data2 = data.table(read.csv(dst2, skip = 4, nrows = 215, stringsAsFactors = FALSE))
data2 <- data2[X != ""]
data2 <- data2[, list(X, X.1, X.3, X.4)]
setnames(data2, c("X", "X.1", "X.3", "X.4"), c("code", "ranking",
"name", "gdp"))
gdp <- as.numeric(gsub(",", "", data2$gdp))
mean(gdp, na.rm = TRUE)
gpd
gdp
!is.na(gdp)
count(data2$name,^United)
countries<-data2$name
^literals
?grep
grep(^United,data2$name)
grep("^United",data2$name)
count(grep("^United",data2$name))
count.fields(grep("^United",data2$name))
length(grep("^United",data2$name))
data2$name
grep("^United",data2$name)
data2$name[c(1,6,32)]
grep("^United",data2$name), 4
grep("^United",data2$name)
url4 = 'https://d396qusza40orc.cloudfront.net/getdata%2Fdata%2FEDSTATS_Country.csv'
dst4 = 'q44.csv'
download.file(url4, dst4, method = 'auto')
data4<-read.csv(dst4)
View(data4)
dt <- merge(data2, data4, all = TRUE, by = c("code","CountryCode"))
data4<-data.table(read.csv(dst4))
dt <- merge(data2, data4, all = TRUE, by = c("code","CountryCode"))
names(data2)
names(data4)
names(data2[1])
names(data2[[1]])
names(data2)[1]
names(data2)[1]<-"CountryCode"
dt <- merge(data2, data4, all = TRUE, by = c("CountryCode"))
dt
?contains
grep(["fiscal year end"."June"],tolower(dt$Special.Notes))
grep("[fiscal year end.June]",tolower(dt$Special.Notes))
dt[3]$Special.Notes
grep("[fiscal year end].[June]",tolower(dt$Special.Notes))
dt[3]$Special.Notes
grep("fiscal year end*June",tolower(dt$Special.Notes))
grep("fiscal year end?June",tolower(dt$Special.Notes))
grep("fiscal year end(*)?June",tolower(dt$Special.Notes))
grep("fiscal year end(.*)?June",tolower(dt$Special.Notes))
grep("[fiscal year end](.*)[June]",tolower(dt$Special.Notes))
dt[10]$Special.Notes
length(grep("[fiscal year end](.*)[June]",tolower(dt$Special.Notes)))
length(grep("fiscal year end(.*)June",tolower(dt$Special.Notes)))
length(grep("[fiscal year end]+(.*)[June]+",tolower(dt$Special.Notes)))
length(grep("fiscal year end(.*)June",tolower(dt$Special.Notes)))
grep("fiscal year end(.*)June",tolower(dt$Special.Notes))
grepl("fiscal year end(.*)June",tolower(dt$Special.Notes))
grepl("fiscal year end(*)June",tolower(dt$Special.Notes))
grep("fiscal year end(.*)June",tolower(dt$Special.Notes))
grep("fiscal year end(.*)June", "Fiscal year end: June 30")
grep("fiscal year end(.*)june",tolower(dt$Special.Notes))
length(grep("fiscal year end(.*)june",tolower(dt$Special.Notes)))
length(grep("fiscal year end(.*)june",tolower(dt$Special.Notes)))
library(quantmod)
amzn = getSymbols("AMZN",auto.assign=FALSE)
amzn
names(amzn)
View(amzn)
sampleTimes = index(amzn)
sampleTimes
detach("package:data.table", unload=TRUE)
library(lubridate)
year(sampleTimes)
length(year(sampleTime)==2012)
length(year(sampleTimes)==2012)
year(sampleTimes)==2012
count(year(sampleTimes)==2012)
length(year(sampleTimes)=2012)
is.true(year(sampleTimes)==2012)
(year(sampleTimes)==2012)==TRUE
sampleTimes[year(sampleTimes)==2012)]
sampleTimes[year(sampleTimes)==2012),]
sampleTimes[(year(sampleTimes)==2012))]
sampleTimes[(year(sampleTimes)==2012)]
sampleTimes[(year(sampleTimes)==2012)].count()
count.sampleTimes[(year(sampleTimes)==2012)]
class(sampleTimes)
addmargins(table(year(sampleTimes), weekdays(sampleTimes)))
?addmargins
###############################################################################
source('C:/Users/Isabel/gitrepos/GettingAndCleaningData/run_analysis.R', echo=TRUE)
head(df)
head(df[,5])
head(dftydy[,5])
head(dftidy[,5])
names(dftidy)
head(dftidy[,5])
head(df[,5])
head(df[,5],5)
View(dftidy)
head(df[,1:5],5)
head(dftidy[,1:5],5)
View(XTrain)
dftidy[dftidy$subjects==5,1:5]
View(df)
View(subjectTrain)
head(dftidy[,1:5],5)
head(dfmean[,1:10],5)
head(dfmean[,1:5],10)
?ddply
View(dfmean)
str(dfmean)
XTrain[1:5,1:5]
complabels
gsub("x$","X$",newlabels)
gsub("x$","X",newlabels)
gsub("y$","Y",newlabels)
complabels
source('C:/Users/Isabel/gitrepos/GettingAndCleaningData/run_analysis.R', echo=TRUE)
list.files("UCI HAR Dataset",recursive=TRUE)
